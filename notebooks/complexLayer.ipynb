{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook shows how to build a complex layer for pytorch's Linear, Conv and ConvTranspose layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pytorch_complex_tensor import ComplexTensor\n",
    "from torch.nn import Conv2d, Linear, ConvTranspose2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic complex wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "class complexLayer(nn.Module):\n",
    "    '''\n",
    "    This class wraps a pytorch layer and turns it into the equivalent \n",
    "    complex layer. So far it works for Linear, Conv and ConvTranspose\n",
    "    \n",
    "    TODO:   1. Code it for RNN layers.\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, Layer,kwargs):\n",
    "        super().__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.bias = kwargs.get('bias',False)\n",
    "        # turn the bias off so as to only do matrix multiplication \n",
    "        # if you leave the bias on, then the complex arithmetic does not \n",
    "        # work out correctly\n",
    "        kwargs['bias'] = False\n",
    "        self.f_re = Layer(**kwargs)\n",
    "        self.f_im = Layer(**kwargs)\n",
    "        self.b = None\n",
    "        out_dim_keyNames = set(['out_channels', 'out_features'])\n",
    "        self.outType = list(out_dim_keyNames.intersection(kwargs.keys()))[0]\n",
    "        self.out_dim = kwargs[self.outType]\n",
    "        if self.bias:\n",
    "            b_r = np.random.randn(self.out_dim,1).astype('float32')\n",
    "            b_i = np.random.randn(self.out_dim,1).astype('float32')\n",
    "            z = b_r + 1j*b_i\n",
    "            self.b = ComplexTensor(z)    \n",
    "\n",
    "    def forward(self, x): \n",
    "        real = self.f_re(x.real) - self.f_im(x.imag)\n",
    "        imaginary = self.f_re(x.imag) + self.f_im(x.real)\n",
    "        if self.bias:\n",
    "            if self.outType == 'out_channels':\n",
    "                # expand the dims\n",
    "                b_r = self.b.real.reshape(1,len(self.b),1,1)\n",
    "                b_i = self.b.imag.reshape(1,len(self.b),1,1)\n",
    "            else:\n",
    "                b_r = self.b.real.reshape(len(self.b),)\n",
    "                b_i = self.b.imag.reshape(len(self.b),)\n",
    "            real = real + b_r\n",
    "            imaginary = imaginary + b_i\n",
    "        result = torch.cat([real, imaginary], dim=-2)\n",
    "        result.__class__ = ComplexTensor\n",
    "        return result\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        result = self.forward(x)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "bz = 16\n",
    "bias = True # vary this for testing purposes\n",
    "x = torch.randn((bz,2,3,100,100))\n",
    "x_np = x.detach().numpy()\n",
    "real = np.squeeze(x_np[:,0,:,:])\n",
    "imag = np.squeeze(x_np[:,1,:,:])\n",
    "z = real + 1j*imag\n",
    "z = ComplexTensor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {'in_channels':3, 'out_channels':10, 'kernel_size':5, 'bias':bias}\n",
    "compConv2D = complexLayer(Conv2d,dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10, 96, 96])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = compConv2D(z)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on ConvTran2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10, 199, 199])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = {'in_channels':3, 'out_channels':10, 'kernel_size':5,'padding':(2,2),'stride':2, 'bias':bias}\n",
    "compConvTran2D = complexLayer(ConvTranspose2d,dct)\n",
    "out = compConvTran2D(z)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on Linear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {'in_features':3, 'out_features':10,'bias':bias}\n",
    "denseLayer = complexLayer(Linear,dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "bz = 16\n",
    "x = torch.randn((bz,2,1,3))\n",
    "x_np = x.detach().numpy()\n",
    "real = np.squeeze(x_np[:,0,:,:])\n",
    "imag = np.squeeze(x_np[:,1,:,:])\n",
    "z = real + 1j*imag\n",
    "z = ComplexTensor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = denseLayer(z)\n",
    "out.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
